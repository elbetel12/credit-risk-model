{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# SHAP Model Interpretability Analysis\n",
                "This notebook contains SHAP (SHapley Additive exPlanations) visualizations to interpret the credit risk model's decisions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import shap\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "import os\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Set style for better visuals\n",
                "try:\n",
                "    plt.style.use('seaborn-v0_8-whitegrid')\n",
                "except:\n",
                "    plt.style.use('ggplot')\n",
                "\n",
                "print(\"Loading data and model...\")\n",
                "# 1. Load Model and Metadata\n",
                "rf_model = joblib.load('models/best_model.pkl')\n",
                "feat_info = joblib.load('models/feature_info.pkl')\n",
                "scaler = joblib.load('models/scaler.pkl')\n",
                "feature_names = feat_info.get('feature_names', [])\n",
                "\n",
                "# 2. Reconstruct X_test (Matching training pipeline)\n",
                "f_df = pd.read_csv('data/processed/customer_features.csv')\n",
                "t_df = pd.read_csv('data/processed/target_variable.csv')\n",
                "merged = f_df.merge(t_df, on='CustomerId', how='inner')\n",
                "\n",
                "# Ensure required feature engineering columns exist\n",
                "if 'avg_amount' not in merged.columns:\n",
                "    merged['avg_amount'] = merged['total_amount'] / merged['transaction_count'].replace(0, 1)\n",
                "    merged['log_total_amount'] = np.log1p(merged['total_amount'].clip(lower=0))\n",
                "    merged['log_transaction_count'] = np.log1p(merged['transaction_count'].clip(lower=0))\n",
                "    merged['avg_txn_size'] = merged['total_amount'] / merged['transaction_count'].replace(0, 1)\n",
                "    merged['amount_category_code'] = pd.cut(merged['total_amount'], bins=[-np.inf, 100, 500, 2000, np.inf], labels=[0, 1, 2, 3]).astype(float)\n",
                "    merged['tx_count_category_code'] = pd.cut(merged['transaction_count'], bins=[-np.inf, 5, 20, 50, np.inf], labels=[0, 1, 2, 3]).astype(float)\n",
                "\n",
                "X = merged[feature_names]\n",
                "y = merged['is_high_risk']\n",
                "_, X_test_raw, _, _ = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\nX_test = pd.DataFrame(scaler.transform(X_test_raw), columns=feature_names)\n",
                "print(f\"Setup complete. X_test shape: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "shap_analysis",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create SHAP explainer\n",
                "explainer = shap.TreeExplainer(rf_model)\n",
                "\n",
                "# Use a sample of test data for faster computation\n",
                "X_sample = X_test.sample(min(200, len(X_test)), random_state=42)\n",
                "\n",
                "# Calculate SHAP values\n",
                "shap_values = explainer.shap_values(X_sample)\n",
                "\n",
                "# Handle binary classification output format differences\n",
                "if isinstance(shap_values, list):\n",
                "    shap_values_risk = shap_values[1] if len(shap_values) > 1 else shap_values[0]\n",
                "    base_value = explainer.expected_value[1] if hasattr(explainer, 'expected_value') and isinstance(explainer.expected_value, (list, np.ndarray)) and len(explainer.expected_value) > 1 else explainer.expected_value\n",
                "else:\n",
                "    shap_values_risk = shap_values\n",
                "    base_value = explainer.expected_value\n",
                "\n",
                "# 1. Summary Plot\n",
                "plt.figure(figsize=(12, 8))\n",
                "shap.summary_plot(shap_values_risk, X_sample, show=False)\n",
                "plt.title('SHAP Summary Plot: Feature Impact on Credit Risk', fontsize=16, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('shap_summary_plot.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "# 2. Find High and Low Risk Examples\n",
                "probabilities = rf_model.predict_proba(X_sample)[:, 1]\n",
                "high_risk_idx = np.argmax(probabilities)\n",
                "low_risk_idx = np.argmin(probabilities)\n",
                "\n",
                "# 3. Waterfall Plot - High Risk customer\n",
                "plt.figure(figsize=(12, 8))\n",
                "try:\n",
                "    exp_high = shap.Explanation(values=shap_values_risk[high_risk_idx], \n",
                "                                base_values=base_value, \n",
                "                                data=X_sample.iloc[high_risk_idx], \n",
                "                                feature_names=X_sample.columns.tolist())\n",
                "    shap.waterfall_plot(exp_high, show=False)\n",
                "except:\n",
                "    shap.waterfall_plot(shap_values_risk[high_risk_idx], show=False)\n",
                "plt.title(f'SHAP Waterfall Plot: High-Risk Customer (Score: {probabilities[high_risk_idx]:.1%})', \n",
                "          fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('shap_waterfall_highrisk.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "# 4. Waterfall Plot - Low Risk customer\n",
                "plt.figure(figsize=(12, 8))\n",
                "try:\n",
                "    exp_low = shap.Explanation(values=shap_values_risk[low_risk_idx], \n",
                "                               base_values=base_value, \n",
                "                               data=X_sample.iloc[low_risk_idx], \n",
                "                               feature_names=X_sample.columns.tolist())\n",
                "    shap.waterfall_plot(exp_low, show=False)\n",
                "except:\n",
                "    shap.waterfall_plot(shap_values_risk[low_risk_idx], show=False)\n",
                "plt.title(f'SHAP Waterfall Plot: Low-Risk Customer (Score: {probabilities[low_risk_idx]:.1%})', \n",
                "          fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('shap_waterfall_lowrisk.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}